{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f478775",
   "metadata": {},
   "source": [
    "# Movie Recommendation with Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074fc674",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1370a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # The torch module to implement the Neural Networks\n",
    "import torch.nn.parallel # For parallel computations\n",
    "import torch.optim as optim # For optimizers\n",
    "import torch.utils.data # Tools\n",
    "from torch.autograd import Variable # For Stochatic Gradient Descent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c5269",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d7e0da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a88414b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Shape: (3883, 3)\n",
      "Users Shape: (6040, 5)\n",
      "Ratings Shape: (1000209, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Movies Shape: {}'.format(movies.shape))\n",
    "print('Users Shape: {}'.format(users.shape))\n",
    "print('Ratings Shape: {}'.format(ratings.shape), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbcc77b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f910e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b01f1",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "372ae739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Movies Dataset\n",
    "movies.drop(columns = 2, inplace = True)\n",
    "movies.columns = ['movie_id','movie']\n",
    "\n",
    "#Ratings Dataset\n",
    "ratings.drop(columns = 3, inplace = True) #removing useless column\n",
    "ratings.columns = ['user_id','movie_id','rating']\n",
    "\n",
    "#Normalization\n",
    "max_rating = max(ratings['rating']) #5\n",
    "min_rating = min(ratings['rating']) #1\n",
    "ratings['rating'] = [((i - min_rating) / (max_rating - min_rating)) for i in ratings['rating']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68df3c",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf218eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (800090, 3)\n",
      "Test Shape: (200119, 3) \n",
      "\n",
      "Users: 6040\n",
      "Movies: 3952\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Train-Test Split\n",
    "training_size = 800090\n",
    "training_set = ratings.iloc[:training_size, :] # Until userID = 4794\n",
    "test_set = ratings.iloc[training_size:, :] # Starting at userID = 4795\n",
    "\n",
    "training_set = training_set.values\n",
    "test_set = test_set.values\n",
    "\n",
    "print('Train Shape: {}'.format(training_set.shape))\n",
    "print('Test Shape: {}'.format(test_set.shape), '\\n')\n",
    "\n",
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0]))) #number of users\n",
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1]))) #number of movies\n",
    "\n",
    "print('Users: {}'.format(nb_users))\n",
    "print('Movies: {}'.format(nb_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c9eda970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def convert(data, nr_observations, nr_entities):\n",
    "        '''\n",
    "        Generates (from a numpy array) a list of lists containing the number of ratings per user (rows), per entity (columns).\n",
    "        Each of the constituent lists will correspond to an observation / user (row).\n",
    "        Each observation list will contain the number of ratings (columns), one for each rating entity\n",
    "        data: Input table (numpy array)\n",
    "        nr_observations: Number of observations\n",
    "        nr_entities: Number of entities rating in each observation\n",
    "        '''\n",
    "        converted_data = []\n",
    "        for id_user in range(1, nr_observations + 1):\n",
    "            id_entity = data[:,1][data[:,0] == id_user].astype(int)\n",
    "            id_ratings = data[:,2][data[:,0] == id_user]\n",
    "            ratings = np.zeros(nr_entities)\n",
    "            ratings[id_entity - 1] = id_ratings\n",
    "            converted_data.append(list(ratings))\n",
    "        return converted_data\n",
    "    \n",
    "training_set = convert(training_set, nb_users, nb_movies)\n",
    "test_set = convert(test_set, nb_users, nb_movies)\n",
    "\n",
    "#Torch Tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58f48af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fd19d",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f34506c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RestrictedBoltzmannMachine():\n",
    "    '''\n",
    "    Restricted Boltzmann Machine (RBM) with 'nh' hidden nodes and 'nv' visible nodes.\n",
    "    '''\n",
    "    def __init__(self, nv, nh):\n",
    "        '''\n",
    "        RBM initialization module where three tensors are defined:\n",
    "        W: Weight tensor\n",
    "        a: Visible node bias tensor\n",
    "        b: Hidden node bias tensor\n",
    "        a and b are created as two-dimensional tensors to accommodate batches of observations over training.\n",
    "        '''\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "\n",
    "        \n",
    "    def sample_h(self, vx):\n",
    "        '''\n",
    "        Method devoted to Gibbs sampling probabilities of hidden nodes given visible nodes - p (h|v)\n",
    "        vx: Input visible node tensor\n",
    "        '''\n",
    "        w_vx = torch.mm(vx, self.W.t())\n",
    "        activation = w_vx + self.a.expand_as(w_vx)\n",
    "        c_p_h_given_v = torch.sigmoid(activation)\n",
    "        return c_p_h_given_v, torch.bernoulli(c_p_h_given_v)\n",
    "\n",
    "    \n",
    "    def sample_v(self, hx):\n",
    "        '''\n",
    "        Method devoted to Gibbs sampling probabilities of visible nodes given hidden nodes - p (v|h)\n",
    "        hx: Input hidden node tensor\n",
    "        '''\n",
    "        w_hx = torch.mm(hx, self.W)\n",
    "        activation = w_hx + self.b.expand_as(w_hx)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        \n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "\n",
    "    \n",
    "    def train(self, nr_observations, nr_epoch, batch_size, train_tensor, metric):\n",
    "        '''\n",
    "        Method through which contrastive divergence-based training is performed.\n",
    "        nr_observations: Number of observations used for training\n",
    "        nr_epoch: Number of training epochs\n",
    "        batch_size: Batch size\n",
    "        train_tensor: Tensor containing training observations\n",
    "        metric: Training performance metric of choice ('MAE' for Mean Absolute Error, 'RMSE' for Root Mean Square Error)\n",
    "        '''\n",
    "        print('Training...')\n",
    "        for epoch in range(1, nr_epoch + 1):\n",
    "            start_time = datetime.now()\n",
    "            print(f'Epoch {str(epoch)} of {str(nr_epoch)} ', end='')\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            \n",
    "            for id_user in range(0, nr_observations - batch_size, batch_size):\n",
    "                v0 = train_tensor[id_user:id_user+batch_size]\n",
    "                vk = train_tensor[id_user:id_user+batch_size]\n",
    "                ph0,_ = self.sample_h(v0)\n",
    "                for k in range(10):\n",
    "                    _,hk = self.sample_h(vk)\n",
    "                    _,vk = self.sample_v(hk)\n",
    "                    vk[v0<0] = v0[v0<0]\n",
    "                    \n",
    "                phk,_ = self.sample_h(vk)\n",
    "                self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "                self.b += torch.sum((v0 - vk), 0)\n",
    "                self.a += torch.sum((ph0 - phk), 0)\n",
    "                \n",
    "                if metric == 'MAE':\n",
    "                    train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "                elif metric == 'RMSE':\n",
    "                    train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2))\n",
    "                s += 1.\n",
    "                \n",
    "            end_time = datetime.now()\n",
    "            time_elapsed = end_time - start_time\n",
    "            time_elapsed = time_elapsed.total_seconds()\n",
    "            print(f'- Loss ({metric}): {train_loss/s:.8f} ({time_elapsed:.2f} seconds)')\n",
    "\n",
    "\n",
    "    def test(self, nr_observations, train_tensor, test_tensor, metric):\n",
    "        '''\n",
    "        Method through which testing is performed.\n",
    "        nr_observations: Number of observations used for testing\n",
    "        train_tensor: Tensor containing training observations\n",
    "        test_tensor: Tensor containing testing observations\n",
    "        metric: Training performance metric of choice ('MAE' for Mean Absolute Error, 'RMSE' for Root Mean Square Error)\n",
    "        '''\n",
    "        print('Testing...')\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        for id_user in range(nr_observations):\n",
    "            c_v = train_tensor[id_user:id_user+1]\n",
    "            vt = test_tensor[id_user:id_user+1]\n",
    "            if len(vt[vt>=0]) > 0:\n",
    "                _,c_h = self.sample_h(c_v)\n",
    "                _,c_v = self.sample_v(c_h)\n",
    "                \n",
    "                if metric == 'MAE':\n",
    "                    test_loss += torch.mean(torch.abs(vt[vt>=0] - c_v[vt>=0]))\n",
    "                elif metric == 'RMSE':\n",
    "                    test_loss += np.sqrt(torch.mean((vt[vt>=0] - c_v[vt>=0])**2))\n",
    "                s += 1.\n",
    "        print(f'Test loss ({metric}): {test_loss/s:.8f}')\n",
    "        \n",
    "        \n",
    "    def predict(self, visible_nodes):\n",
    "        '''\n",
    "        Method through which predictions for one specific observation are derived.\n",
    "        visible_nodes: Tensor containing one particular observation (set of values for each visible node) \n",
    "        '''\n",
    "        h_v,_ = self.sample_h(visible_nodes)\n",
    "        v_h,_ = self.sample_v(h_v)\n",
    "        \n",
    "        return v_h\n",
    "    \n",
    "def movie_recommender(movie_list, train_set, test_set, model, user_id):\n",
    "        '''\n",
    "        Generates movie recommendations for a particular platform user. \n",
    "        movie_list: List of movies and corresponding IDs\n",
    "        train_set: Tensor containing training observations\n",
    "        test_set: Tensor containing testing observations\n",
    "        model: A RBM machine learning model previously instantiated\n",
    "        user_id: The user for which preferred movies will be assessed and recommendations will be provided\n",
    "        '''\n",
    "        if user_id < 4795:\n",
    "            user_sample = train_set[user_id - 1:user_id]\n",
    "        else:\n",
    "            user_sample = test_set[user_id - 1:user_id]\n",
    "            \n",
    "        pred = model.predict(user_sample).numpy()\n",
    "        user_sample = user_sample.numpy()\n",
    "        user_sample = pd.Series(user_sample[0])\n",
    "        user_sample = user_sample.sort_values(ascending=False)\n",
    "        user_sample = user_sample.iloc[:5]\n",
    "        movie_indices = user_sample.index.values.tolist()\n",
    "        print('Favourite movies of User {}\\n'.format(user_id))\n",
    "        \n",
    "        for fav_movie_id in movie_indices:\n",
    "            print(movie_list[movie_list.movie_id == fav_movie_id + 1].iloc[0][1])\n",
    "        pred = pd.Series(pred[0])\n",
    "        pred = pred.sort_values(ascending=False)\n",
    "        pred_list = pred.index.values.tolist()\n",
    "        print('\\nUser {} may also like these movies\\n'.format(user_id))\n",
    "        \n",
    "        nb_recommendations = 0\n",
    "        i = 0\n",
    "        while nb_recommendations < 5:\n",
    "            pred_movie = pred_list[i]\n",
    "            if pred_movie not in movie_indices:\n",
    "                print(movie_list[movie_list.movie_id == pred_movie + 1].iloc[0][1])\n",
    "                nb_recommendations += 1\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6896ef",
   "metadata": {},
   "source": [
    "## Training RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "305f93f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1 of 20 - Loss (MAE): 0.03920628 (33.90 seconds)\n",
      "Epoch 2 of 20 - Loss (MAE): 0.03742308 (36.51 seconds)\n",
      "Epoch 3 of 20 - Loss (MAE): 0.03740079 (47.57 seconds)\n",
      "Epoch 4 of 20 - Loss (MAE): 0.03739331 (84.77 seconds)\n",
      "Epoch 5 of 20 - Loss (MAE): 0.03719060 (62.54 seconds)\n",
      "Epoch 6 of 20 - Loss (MAE): 0.03698669 (39.32 seconds)\n",
      "Epoch 7 of 20 - Loss (MAE): 0.03692999 (52.98 seconds)\n",
      "Epoch 8 of 20 - Loss (MAE): 0.03676546 (84.24 seconds)\n",
      "Epoch 9 of 20 - Loss (MAE): 0.03670770 (31.47 seconds)\n",
      "Epoch 10 of 20 - Loss (MAE): 0.03663136 (34.96 seconds)\n",
      "Epoch 11 of 20 - Loss (MAE): 0.03655441 (30.71 seconds)\n",
      "Epoch 12 of 20 - Loss (MAE): 0.03652532 (31.88 seconds)\n",
      "Epoch 13 of 20 - Loss (MAE): 0.03656529 (29.88 seconds)\n",
      "Epoch 14 of 20 - Loss (MAE): 0.03662478 (29.91 seconds)\n",
      "Epoch 15 of 20 - Loss (MAE): 0.03654826 (30.00 seconds)\n",
      "Epoch 16 of 20 - Loss (MAE): 0.03652560 (29.68 seconds)\n",
      "Epoch 17 of 20 - Loss (MAE): 0.03651884 (29.79 seconds)\n",
      "Epoch 18 of 20 - Loss (MAE): 0.03650099 (29.40 seconds)\n",
      "Epoch 19 of 20 - Loss (MAE): 0.03646689 (29.28 seconds)\n",
      "Epoch 20 of 20 - Loss (MAE): 0.03637288 (29.79 seconds)\n",
      "Testing...\n",
      "Test loss (MAE): 0.02499655\n",
      "Wall time: 13min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 5\n",
    "epoch = 20\n",
    "metric = 'MAE'\n",
    "\n",
    "rbm = RestrictedBoltzmannMachine(nv, nh)\n",
    "rbm.train(nb_users, epoch, batch_size, training_set, metric)\n",
    "rbm.test(nb_users, training_set, test_set, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f5d2076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favourite movies of User 12\n",
      "\n",
      "Raiders of the Lost Ark (1981)\n",
      "Taxi Driver (1976)\n",
      "Godfather: Part II, The (1974)\n",
      "Christmas Story, A (1983)\n",
      "Silence of the Lambs, The (1991)\n",
      "\n",
      "User 12 may also like these movies\n",
      "\n",
      "Casablanca (1942)\n",
      "American Beauty (1999)\n",
      "Sixth Sense, The (1999)\n",
      "Hustler, The (1961)\n",
      "8 1/2 (1963)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(movie_recommender(movies, training_set, test_set, rbm, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85aaca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favourite movies of User 10\n",
      "\n",
      "Toy Story (1995)\n",
      "Mary Poppins (1964)\n",
      "Cinderella (1950)\n",
      "Shaggy Dog, The (1959)\n",
      "Escape to Witch Mountain (1975)\n",
      "\n",
      "User 10 may also like these movies\n",
      "\n",
      "Sixth Sense, The (1999)\n",
      "American Beauty (1999)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Hunt for Red October, The (1990)\n",
      "Fargo (1996)\n"
     ]
    }
   ],
   "source": [
    "movie_recommender(movies, training_set, test_set, rbm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cba2bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favourite movies of User 4888\n",
      "\n",
      "Cabaret (1972)\n",
      "Lawrence of Arabia (1962)\n",
      "Little Big Man (1970)\n",
      "Blade Runner (1982)\n",
      "Apocalypse Now (1979)\n",
      "\n",
      "User 4888 may also like these movies\n",
      "\n",
      "Casablanca (1942)\n",
      "Hustler, The (1961)\n",
      "Jules and Jim (Jules et Jim) (1961)\n",
      "Midnight Cowboy (1969)\n",
      "8 1/2 (1963)\n"
     ]
    }
   ],
   "source": [
    "movie_recommender(movies, training_set, test_set, rbm, 4888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f43cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
